<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Voice Chat</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      min-height: 100vh;
      background-color: #f0f2f5;
      color: #333;
      padding: 20px;
      box-sizing: border-box;
    }
    .button-container {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
    }
    button {
      padding: 12px 24px;
      font-size: 1rem;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: background-color 0.3s, transform 0.2s, box-shadow 0.3s;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
    }
    button#startBtn {
      background-color: #007bff;
      color: white;
    }
    button#stopBtn {
      background-color: #dc3545;
      color: white;
    }
    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
    }
    button:disabled {
      background-color: #ccc;
      color: #666;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }
    #status {
      font-size: 1.2rem;
      font-weight: bold;
      margin-top: 10px;
      padding: 15px;
      background-color: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      text-align: center;
      width: 100%;
      box-sizing: border-box;
    }
    @media (max-width: 600px) {
      body { padding: 10px; }
      .button-container {
        flex-direction: column;
        width: 100%;
      }
      button {
        width: 100%;
        margin-bottom: 10px;
      }
      #status {
        font-size: 1rem;
      }
    }
  </style>
</head>
<body>

  <div class="button-container">
    <button id="startBtn">Start Talking</button>
    <button id="stopBtn" disabled>Stop</button>
  </div>
  <div id="status">Idle</div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusDiv = document.getElementById('status');

    let audioContext;
    let mediaStream;
    let vadProcessor;
    let vadRunning = false;
    let isRecording = false;
    let silenceTimeout;
    let audioPlayback = new Audio();

    const VAD_THRESHOLD = 0.05;
    const SILENCE_TIMEOUT = 1000;

    let pcmChunks = [];
    let recorderNode;

    startBtn.onclick = startVoiceChat;
    stopBtn.onclick = stopVoiceChat;

    async function startVoiceChat() {
      startBtn.disabled = true;
      stopBtn.disabled = false;
      statusDiv.textContent = 'Initializing microphone...';

      try {
        audioContext = new AudioContext({ sampleRate: 16000 });
        mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const source = audioContext.createMediaStreamSource(mediaStream);

        vadProcessor = audioContext.createScriptProcessor(4096, 1, 1);
        vadProcessor.onaudioprocess = vadAudioProcess;

        source.connect(vadProcessor);
        vadProcessor.connect(audioContext.destination);

        vadRunning = false;
        setTimeout(() => {
          vadRunning = true;
          statusDiv.textContent = 'Listening for voice... Speak now.';
        }, 1000);
      } catch (error) {
        console.error("Error starting voice chat:", error);
        statusDiv.textContent = `Error: ${error.message}. Please ensure microphone access is enabled.`;
        startBtn.disabled = false;
        stopBtn.disabled = true;
      }
    }

    function stopVoiceChat() {
      startBtn.disabled = false;
      stopBtn.disabled = true;
      statusDiv.textContent = 'Stopped.';
      vadRunning = false;
      clearTimeout(silenceTimeout);

      if (vadProcessor) {
        vadProcessor.disconnect();
        vadProcessor.onaudioprocess = null;
        vadProcessor = null;
      }
      if (recorderNode) {
        recorderNode.disconnect();
        recorderNode.onaudioprocess = null;
        recorderNode = null;
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }

      isRecording = false;
      pcmChunks = [];

      audioPlayback.pause();
      audioPlayback.src = '';
      audioPlayback.onended = null;
    }

    function vadAudioProcess(event) {
      if (!vadRunning) return;

      const inputData = event.inputBuffer.getChannelData(0);
      let sum = 0.0;
      for (let i = 0; i < inputData.length; i++) {
        sum += inputData[i] * inputData[i];
      }
      const rms = Math.sqrt(sum / inputData.length);

      if (rms > VAD_THRESHOLD) {
        statusDiv.textContent = 'Voice detected, recording...';

        if (silenceTimeout) {
          clearTimeout(silenceTimeout);
          silenceTimeout = null;
        }

        if (!isRecording) startRecording();
      } else {
        if (isRecording && !silenceTimeout) {
          silenceTimeout = setTimeout(() => {
            stopRecording();
            silenceTimeout = null;
          }, SILENCE_TIMEOUT);
          statusDiv.textContent = 'Silence detected, waiting...';
        }
      }
    }

    function startRecording() {
      pcmChunks = [];
      const source = audioContext.createMediaStreamSource(mediaStream);
      recorderNode = audioContext.createScriptProcessor(4096, 1, 1);

      recorderNode.onaudioprocess = e => {
        const input = e.inputBuffer.getChannelData(0);
        pcmChunks.push(new Float32Array(input));
      };

      source.connect(recorderNode);
      recorderNode.connect(audioContext.destination);

      isRecording = true;
    }

    function stopRecording() {
      if (!isRecording) return;
      isRecording = false;
      recorderNode.disconnect();
      recorderNode.onaudioprocess = null;

      handleRecordingStop();
    }

    function flattenFloat32Arrays(chunks) {
      const length = chunks.reduce((acc, chunk) => acc + chunk.length, 0);
      const result = new Float32Array(length);
      let offset = 0;
      for (const chunk of chunks) {
        result.set(chunk, offset);
        offset += chunk.length;
      }
      return result;
    }

    function encodeWAV(samples, sampleRate = 16000) {
      const buffer = new ArrayBuffer(44 + samples.length * 2);
      const view = new DataView(buffer);

      function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }

      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + samples.length * 2, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, samples.length * 2, true);

      for (let i = 0; i < samples.length; i++) {
        const s = Math.max(-1, Math.min(1, samples[i]));
        view.setInt16(44 + i * 2, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
      }

      return new Blob([view], { type: 'audio/wav' });
    }

    async function handleRecordingStop() {
      vadRunning = false;
      statusDiv.textContent = 'Processing audio...';

      const samples = flattenFloat32Arrays(pcmChunks);
      const wavBlob = encodeWAV(samples);

      try {
        const formData = new FormData();
        formData.append('file', wavBlob, 'audio.wav');

        const response = await fetch('https://speech-to-speech-spm6.onrender.com/voicechat', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error('Server error: ' + response.statusText);
        }

        const transcription = response.headers.get('X-Transcript') || '';
        statusDiv.textContent = `You said: "${transcription}". Playing response...`;

        const audioResponseBlob = await response.blob();
        audioPlayback.src = URL.createObjectURL(audioResponseBlob);
        audioPlayback.play();

        audioPlayback.onended = () => {
        if (!vadRunning && mediaStream && audioContext) {
          const source = audioContext.createMediaStreamSource(mediaStream);
      
          vadProcessor = audioContext.createScriptProcessor(4096, 1, 1);
          vadProcessor.onaudioprocess = vadAudioProcess;
      
          source.connect(vadProcessor);
          vadProcessor.connect(audioContext.destination);
      
          vadRunning = true;
          statusDiv.textContent = 'Listening for voice... Speak now.';
        }
      };

      } catch (error) {
        statusDiv.textContent = 'Error: ' + error.message;
        vadRunning = true;
      }
    }
  </script>
</body>
</html>
