<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Professional Voice Chat</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    
    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%);
      min-height: 100vh;
      display: flex;
      align-items: center;
      justify-content: center;
      color: white;
    }
    
    .voice-container {
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(30px);
      border: 1px solid rgba(255, 255, 255, 0.2);
      border-radius: 24px;
      padding: 40px;
      width: 100%;
      max-width: 500px;
      box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
    }
    
    .title {
      text-align: center;
      font-size: 2rem;
      font-weight: 700;
      margin-bottom: 30px;
      background: linear-gradient(45deg, #fff, #e0e0e0);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
    }
    
    .controls {
      display: flex;
      gap: 20px;
      justify-content: center;
      margin-bottom: 30px;
    }
    
    .btn {
      padding: 16px 32px;
      border: none;
      border-radius: 50px;
      font-size: 1.1rem;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      position: relative;
      overflow: hidden;
      min-width: 140px;
    }
    
    .btn-start {
      background: linear-gradient(135deg, #00d4ff, #0099cc);
      color: white;
      box-shadow: 0 8px 32px rgba(0, 212, 255, 0.3);
    }
    
    .btn-stop {
      background: linear-gradient(135deg, #ff4757, #c44569);
      color: white;
      box-shadow: 0 8px 32px rgba(255, 71, 87, 0.3);
    }
    
    .btn:hover:not(:disabled) {
      transform: translateY(-2px);
      box-shadow: 0 12px 40px rgba(0, 0, 0, 0.4);
    }
    
    .btn:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      transform: none;
    }
    
    .status-panel {
      background: rgba(255, 255, 255, 0.1);
      border-radius: 16px;
      padding: 24px;
      text-align: center;
      margin-bottom: 30px;
      border: 1px solid rgba(255, 255, 255, 0.1);
    }
    
    .status-text {
      font-size: 1.2rem;
      font-weight: 500;
      margin-bottom: 10px;
    }
    
    .transcription {
      font-size: 0.95rem;
      opacity: 0.8;
      font-style: italic;
      min-height: 20px;
    }
    
    .audio-visualizer {
      height: 80px;
      background: rgba(255, 255, 255, 0.05);
      border-radius: 12px;
      margin-bottom: 30px;
      position: relative;
      overflow: hidden;
      display: none;
    }
    
    .wave-container {
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100%;
      gap: 3px;
    }
    
    .wave-bar {
      width: 4px;
      background: linear-gradient(to top, #00d4ff, #0099cc);
      border-radius: 2px;
      transition: height 0.1s ease;
      height: 10px;
    }
    
    .recording-pulse {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: 20px;
      height: 20px;
      background: #ff4757;
      border-radius: 50%;
      display: none;
    }
    
    .recording-pulse::before {
      content: '';
      position: absolute;
      top: -10px;
      left: -10px;
      right: -10px;
      bottom: -10px;
      border: 2px solid #ff4757;
      border-radius: 50%;
      animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
      0% { opacity: 1; transform: scale(1); }
      100% { opacity: 0; transform: scale(2); }
    }
    
    .quality-indicators {
      display: flex;
      justify-content: space-between;
      font-size: 0.85rem;
      opacity: 0.7;
    }
    
    .indicator {
      display: flex;
      align-items: center;
      gap: 8px;
    }
    
    .indicator-dot {
      width: 8px;
      height: 8px;
      border-radius: 50%;
      background: #00d4ff;
    }
    
    @media (max-width: 600px) {
      .voice-container {
        margin: 20px;
        padding: 30px 20px;
      }
      
      .controls {
        flex-direction: column;
      }
      
      .btn {
        width: 100%;
      }
    }
  </style>
</head>
<body>
  <div class="voice-container">
    <h1 class="title">üéôÔ∏è Pro Voice Chat</h1>
    
    <div class="controls">
      <button id="startBtn" class="btn btn-start">‚ñ∂ Start Recording</button>
      <button id="stopBtn" class="btn btn-stop" disabled>‚èπ Stop</button>
    </div>
    
    <div class="status-panel">
      <div id="status" class="status-text">Ready to record professional quality audio</div>
      <div id="transcription" class="transcription"></div>
    </div>
    
    <div id="visualizer" class="audio-visualizer">
      <div class="wave-container" id="waveContainer"></div>
      <div class="recording-pulse" id="recordingPulse"></div>
    </div>
    
    <div class="quality-indicators">
      <div class="indicator">
        <div class="indicator-dot"></div>
        <span>48kHz Sampling</span>
      </div>
      <div class="indicator">
        <div class="indicator-dot"></div>
        <span>Noise Reduction</span>
      </div>
      <div class="indicator">
        <div class="indicator-dot"></div>
        <span>Real-time VAD</span>
      </div>
    </div>
  </div>

  <script>
    class ProfessionalAudioRecorder {
      constructor() {
        this.audioContext = null;
        this.mediaStream = null;
        this.audioWorkletNode = null;
        this.recordedChunks = [];
        this.isRecording = false;
        this.isListening = false;
        this.silenceTimer = null;
        this.vadThreshold = 0.01;
        this.silenceTimeout = 2500;
        this.sampleRate = 48000;
        
        // UI Elements
        this.startBtn = document.getElementById('startBtn');
        this.stopBtn = document.getElementById('stopBtn');
        this.status = document.getElementById('status');
        this.transcription = document.getElementById('transcription');
        this.visualizer = document.getElementById('visualizer');
        this.waveContainer = document.getElementById('waveContainer');
        this.recordingPulse = document.getElementById('recordingPulse');
        
        this.setupUI();
        this.createWaveBars();
      }
      
      setupUI() {
        this.startBtn.addEventListener('click', () => this.start());
        this.stopBtn.addEventListener('click', () => this.stop());
      }
      
      createWaveBars() {
        for (let i = 0; i < 32; i++) {
          const bar = document.createElement('div');
          bar.className = 'wave-bar';
          this.waveContainer.appendChild(bar);
        }
      }
      
      async start() {
        try {
          this.startBtn.disabled = true;
          this.stopBtn.disabled = false;
          this.updateStatus('üé§ Initializing professional audio system...');
          
          // Get high-quality audio stream
          this.mediaStream = await navigator.mediaDevices.getUserMedia({
            audio: {
              sampleRate: this.sampleRate,
              channelCount: 1,
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
              googEchoCancellation: true,
              googAutoGainControl: true,
              googNoiseSuppression: true,
              googHighpassFilter: true,
              googAudioMirroring: false
            }
          });
          
          // Create high-performance audio context
          this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: this.sampleRate,
            latencyHint: 'interactive'
          });
          
          // Load and setup AudioWorklet for professional processing
          await this.setupAudioWorklet();
          
          this.visualizer.style.display = 'block';
          this.isListening = true;
          this.updateStatus('üëÇ Listening with professional quality... Speak now!');
          
        } catch (error) {
          console.error('Error starting professional recorder:', error);
          this.updateStatus(`‚ùå Error: ${error.message}`);
          this.reset();
        }
      }
      
      async setupAudioWorklet() {
        // Create AudioWorklet processor inline
        const processorCode = `
          class AudioProcessor extends AudioWorkletProcessor {
            constructor() {
              super();
              this.bufferSize = 0;
              this.buffer = new Float32Array(16384);
              this.isRecording = false;
              
              this.port.onmessage = (e) => {
                if (e.data.command === 'start') {
                  this.isRecording = true;
                  this.bufferSize = 0;
                } else if (e.data.command === 'stop') {
                  this.isRecording = false;
                  if (this.bufferSize > 0) {
                    this.port.postMessage({
                      type: 'audiodata',
                      data: this.buffer.slice(0, this.bufferSize)
                    });
                  }
                }
              };
            }
            
            process(inputs, outputs, parameters) {
              const input = inputs[0];
              if (input.length > 0) {
                const inputData = input[0];
                
                // Calculate RMS for voice activity detection
                let sum = 0;
                for (let i = 0; i < inputData.length; i++) {
                  sum += inputData[i] * inputData[i];
                }
                const rms = Math.sqrt(sum / inputData.length);
                
                // Send audio level for visualization
                this.port.postMessage({
                  type: 'audiolevel',
                  level: rms
                });
                
                // Buffer audio data when recording
                if (this.isRecording && this.bufferSize + inputData.length < this.buffer.length) {
                  this.buffer.set(inputData, this.bufferSize);
                  this.bufferSize += inputData.length;
                }
              }
              
              return true;
            }
          }
          
          registerProcessor('audio-processor', AudioProcessor);
        `;
        
        const blob = new Blob([processorCode], { type: 'application/javascript' });
        const processorUrl = URL.createObjectURL(blob);
        
        try {
          await this.audioContext.audioWorklet.addModule(processorUrl);
          
          // Create and connect AudioWorklet
          this.audioWorkletNode = new AudioWorkletNode(this.audioContext, 'audio-processor');
          const source = this.audioContext.createMediaStreamSource(this.mediaStream);
          
          source.connect(this.audioWorkletNode);
          this.audioWorkletNode.connect(this.audioContext.destination);
          
          // Handle messages from AudioWorklet
          this.audioWorkletNode.port.onmessage = (e) => {
            if (e.data.type === 'audiolevel') {
              this.updateVisualization(e.data.level);
              this.handleVoiceActivity(e.data.level);
            } else if (e.data.type === 'audiodata') {
              this.processRecordedAudio(e.data.data);
            }
          };
          
        } finally {
          URL.revokeObjectURL(processorUrl);
        }
      }
      
      updateVisualization(level) {
        const bars = this.waveContainer.querySelectorAll('.wave-bar');
        const normalizedLevel = Math.min(level * 100, 1);
        
        bars.forEach((bar, index) => {
          const height = Math.random() * normalizedLevel * 60 + 10; // Add some randomness for visual appeal
          bar.style.height = `${height}px`;
        });
      }
      
      handleVoiceActivity(level) {
        if (!this.isListening) return;
        
        if (level > this.vadThreshold) {
          if (!this.isRecording) {
            this.startRecording();
          }
          // Clear silence timer
          if (this.silenceTimer) {
            clearTimeout(this.silenceTimer);
            this.silenceTimer = null;
          }
        } else if (this.isRecording) {
          // Start silence timer
          if (!this.silenceTimer) {
            this.silenceTimer = setTimeout(() => {
              this.stopRecording();
            }, this.silenceTimeout);
          }
        }
      }
      
      startRecording() {
        if (this.isRecording) return;
        
        this.isRecording = true;
        this.recordedChunks = [];
        this.recordingPulse.style.display = 'block';
        this.updateStatus('üî¥ Recording with professional quality...');
        
        // Send start command to AudioWorklet
        this.audioWorkletNode.port.postMessage({ command: 'start' });
      }
      
      stopRecording() {
        if (!this.isRecording) return;
        
        this.isRecording = false;
        this.recordingPulse.style.display = 'none';
        this.updateStatus('‚ö° Processing with advanced algorithms...');
        
        // Send stop command to AudioWorklet
        this.audioWorkletNode.port.postMessage({ command: 'stop' });
        
        if (this.silenceTimer) {
          clearTimeout(this.silenceTimer);
          this.silenceTimer = null;
        }
      }
      
      async processRecordedAudio(audioData) {
        try {
          // Convert Float32Array to WAV
          const wavBuffer = this.encodeWAV(audioData, this.sampleRate);
          const blob = new Blob([wavBuffer], { type: 'audio/wav' });
          
          // Send to server
          const formData = new FormData();
          formData.append('file', blob, 'professional_voice.wav');
          
          const response = await fetch('https://speech-to-speech-1pnl.onrender.com/voicechat', {
            method: 'POST',
            body: formData
          });
          
          if (!response.ok) {
            throw new Error(`Server error: ${response.status}`);
          }
          
          const transcriptionText = response.headers.get('X-Transcript') || '';
          this.transcription.textContent = `"${transcriptionText}"`;
          this.updateStatus('üîä Playing crystal clear response...');
          
          const audioBlob = await response.blob();
          const audio = new Audio(URL.createObjectURL(audioBlob));
          
          audio.onended = () => {
            this.updateStatus('üëÇ Listening with professional quality... Speak now!');
          };
          
          await audio.play();
          
        } catch (error) {
          console.error('Processing error:', error);
          this.updateStatus(`‚ùå Error: ${error.message}`);
          setTimeout(() => {
            this.updateStatus('üëÇ Listening with professional quality... Speak now!');
          }, 3000);
        }
      }
      
      encodeWAV(samples, sampleRate) {
        const buffer = new ArrayBuffer(44 + samples.length * 2);
        const view = new DataView(buffer);
        
        // WAV header
        const writeString = (offset, string) => {
          for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
          }
        };
        
        writeString(0, 'RIFF');
        view.setUint32(4, 36 + samples.length * 2, true);
        writeString(8, 'WAVE');
        writeString(12, 'fmt ');
        view.setUint32(16, 16, true);
        view.setUint16(20, 1, true);
        view.setUint16(22, 1, true);
        view.setUint32(24, sampleRate, true);
        view.setUint32(28, sampleRate * 2, true);
        view.setUint16(32, 2, true);
        view.setUint16(34, 16, true);
        writeString(36, 'data');
        view.setUint32(40, samples.length * 2, true);
        
        // Convert float samples to 16-bit PCM
        let offset = 44;
        for (let i = 0; i < samples.length; i++, offset += 2) {
          const sample = Math.max(-1, Math.min(1, samples[i]));
          view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
        }
        
        return buffer;
      }
      
      updateStatus(message) {
        this.status.textContent = message;
      }
      
      stop() {
        this.isListening = false;
        this.reset();
        this.updateStatus('‚èπÔ∏è Professional recording stopped');
      }
      
      reset() {
        this.startBtn.disabled = false;
        this.stopBtn.disabled = true;
        this.visualizer.style.display = 'none';
        this.recordingPulse.style.display = 'none';
        
        if (this.silenceTimer) {
          clearTimeout(this.silenceTimer);
          this.silenceTimer = null;
        }
        
        if (this.audioWorkletNode) {
          this.audioWorkletNode.disconnect();
          this.audioWorkletNode = null;
        }
        
        if (this.mediaStream) {
          this.mediaStream.getTracks().forEach(track => track.stop());
          this.mediaStream = null;
        }
        
        if (this.audioContext && this.audioContext.state !== 'closed') {
          this.audioContext.close();
          this.audioContext = null;
        }
        
        this.isRecording = false;
      }
    }
    
    // Initialize the professional recorder
    const recorder = new ProfessionalAudioRecorder();
  </script>
</body>
</html>
