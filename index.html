<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Voice Chat</title>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      min-height: 100vh;
      background-color: #f0f2f5;
      color: #333;
      padding: 20px;
      box-sizing: border-box; /* Important for padding to be included in width */
    }

    /* Button Styles */
    .button-container {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
    }

    button {
      padding: 12px 24px;
      font-size: 1rem;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: background-color 0.3s, transform 0.2s, box-shadow 0.3s;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
    }

    button#startBtn {
      background-color: #007bff;
      color: white;
    }

    button#stopBtn {
      background-color: #dc3545;
      color: white;
    }

    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
    }

    button:disabled {
      background-color: #ccc;
      color: #666;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }


    /* Status Display */
    #status {
      font-size: 1.2rem;
      font-weight: bold;
      margin-top: 10px;
      padding: 15px;
      background-color: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      text-align: center;
      width: 100%; /* Take full width of the container */
      box-sizing: border-box; /* Include padding and border in the element's total width and height */
    }


    /* Media Queries for Responsiveness */
    @media (max-width: 600px) {
      body {
        padding: 10px;
      }

      .button-container {
        flex-direction: column;
        width: 100%;  /* Stack buttons vertically */
      }

      button {
        width: 100%; /* Each button takes full width on smaller screens */
        margin-right: 0; /* Remove right margin when stacked */
        margin-bottom: 10px;  /* Add spacing between stacked buttons */
      }

      #status {
        font-size: 1rem;
      }
    }
  </style>
</head>
<body>

  <div class="button-container">
    <button id="startBtn">Start Talking</button>
    <button id="stopBtn" disabled>Stop</button>
  </div>
  <div id="status">Idle</div>

  <script>
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const statusDiv = document.getElementById('status');

    let audioContext;
    let mediaStream;
    let mediaRecorder;
    let audioChunks = [];
    let vadProcessor;
    let vadRunning = false;
    let isRecording = false;
    let silenceTimeout;
    let audioPlayback = new Audio();

    const VAD_THRESHOLD = 0.05;
    const SILENCE_DELAY = 1500;

    startBtn.onclick = startVoiceChat;
    stopBtn.onclick = stopVoiceChat;

    async function startVoiceChat() {
      startBtn.disabled = true;
      stopBtn.disabled = false;
      statusDiv.textContent = 'Initializing microphone...';

      try {
          audioContext = new AudioContext();
          mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const source = audioContext.createMediaStreamSource(mediaStream);

          vadProcessor = audioContext.createScriptProcessor(4096, 1, 1);
          vadProcessor.onaudioprocess = vadAudioProcess;

          source.connect(vadProcessor);
          vadProcessor.connect(audioContext.destination);

          vadRunning = false;
          setTimeout(() => {
            vadRunning = true;
            statusDiv.textContent = 'Listening for voice... Speak now.';
          }, 1000);
      } catch (error) {
          console.error("Error starting voice chat:", error);
          statusDiv.textContent = `Error: ${error.message}. Please ensure microphone access is enabled.`;
          startBtn.disabled = false;
          stopBtn.disabled = true;
      }
    }

    function stopVoiceChat() {
      startBtn.disabled = false;
      stopBtn.disabled = true;
      statusDiv.textContent = 'Stopped.';
      vadRunning = false;
      clearTimeout(silenceTimeout);

      if (vadProcessor) {
        vadProcessor.disconnect();
        vadProcessor.onaudioprocess = null;
        vadProcessor = null;
      }
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
      if (mediaStream) {
        mediaStream.getTracks().forEach(track => track.stop());
        mediaStream = null;
      }
      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }

      isRecording = false;

      audioPlayback.pause();
      audioPlayback.src = '';
      audioPlayback.onended = null;
    }

    let silenceTimer = null;
    const SILENCE_TIMEOUT = 1000;

    function vadAudioProcess(event) {
      if (!vadRunning) return;

      const inputData = event.inputBuffer.getChannelData(0);
      let sum = 0.0;
      for (let i = 0; i < inputData.length; i++) {
        sum += inputData[i] * inputData[i];
      }
      const rms = Math.sqrt(sum / inputData.length);

      if (rms > VAD_THRESHOLD) {

        statusDiv.textContent = 'Voice detected, recording...';

        if (silenceTimer) {
          clearTimeout(silenceTimer);
          silenceTimer = null;
        }

        if (!isRecording) {
          startRecording();
        }
      } else {

        if (isRecording && !silenceTimer) {

          silenceTimer = setTimeout(() => {
            stopRecording();
            silenceTimer = null;
          }, SILENCE_TIMEOUT);

          statusDiv.textContent = 'Silence detected, waiting...';
        }
      }
    }

    function startRecording() {
      audioChunks = [];
      mediaRecorder = new MediaRecorder(mediaStream);
      mediaRecorder.ondataavailable = e => {
        if (e.data.size > 0) audioChunks.push(e.data);
      };
      mediaRecorder.onstop = handleRecordingStop;
      mediaRecorder.start();
      isRecording = true;
    }

    function stopRecording() {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
      }
      isRecording = false;
    }

    async function handleRecordingStop() {

      vadRunning = false;
      statusDiv.textContent = 'Processing audio...';

      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      try {
        const formData = new FormData();
        formData.append('file', audioBlob, 'voice.webm');

        const response = await fetch('http://127.0.0.1:8000/voicechat', {
          method: 'POST',
          body: formData,
        });

        if (!response.ok) {
          throw new Error('Server error: ' + response.statusText);
        }

        const transcription = response.headers.get('X-Transcript') || '';
        statusDiv.textContent = `You said: "${transcription}". Playing response...`;

        const audioResponseBlob = await response.blob();
        audioPlayback.src = URL.createObjectURL(audioResponseBlob);

        audioPlayback.play();

        audioPlayback.onended = () => {
          if (vadRunning === false && mediaStream) {

            vadRunning = true;
            statusDiv.textContent = 'Listening for voice... Speak now.';
          }
        };

      } catch (error) {
        statusDiv.textContent = 'Error: ' + error.message;

        vadRunning = true;
      }
    }
  </script>

</body>
</html>
