<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Voice Chat</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/recorderjs/0.1.0/recorder.min.js"></script>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      margin: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: flex-start;
      min-height: 100vh;
      background-color: #f0f2f5;
      color: #333;
      padding: 20px;
      box-sizing: border-box;
    }
    .button-container {
      display: flex;
      gap: 10px;
      margin-bottom: 20px;
    }
    button {
      padding: 12px 24px;
      font-size: 1rem;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      transition: background-color 0.3s, transform 0.2s, box-shadow 0.3s;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
    }
    button#startBtn {
      background-color: #007bff;
      color: white;
    }
    button#stopBtn {
      background-color: #dc3545;
      color: white;
    }
    button:hover {
      transform: translateY(-2px);
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
    }
    button:disabled {
      background-color: #ccc;
      color: #666;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }
    #status {
      font-size: 1.2rem;
      font-weight: bold;
      margin-top: 10px;
      padding: 15px;
      background-color: #fff;
      border-radius: 8px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      text-align: center;
      width: 100%;
      box-sizing: border-box;
    }
    @media (max-width: 600px) {
      body { padding: 10px; }
      .button-container {
        flex-direction: column;
        width: 100%;
      }
      button {
        width: 100%;
        margin-bottom: 10px;
      }
      #status {
        font-size: 1rem;
      }
    }
  </style>
</head>
<body>

  <div class="button-container">
    <button id="startBtn">Start Talking</button>
    <button id="stopBtn" disabled>Stop</button>
  </div>
  <div id="status">Idle</div>

  <script>
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const statusDiv = document.getElementById('status');

  let audioContext;
  let mediaStream;
  let vadProcessor;
  let vadRunning = false;
  let isRecording = false;
  let silenceTimeout;
  let recorder; // Recorder.js instance
  let inputNode;
  let audioPlayback;

  const VAD_THRESHOLD = 0.05;
  const SILENCE_TIMEOUT = 1000;

  startBtn.onclick = startVoiceChat;
  stopBtn.onclick = stopVoiceChat;

  async function startVoiceChat() {
    startBtn.disabled = true;
    stopBtn.disabled = false;
    statusDiv.textContent = 'Initializing microphone...';

    try {
      audioContext = new AudioContext({ sampleRate: 16000 });
      mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const source = audioContext.createMediaStreamSource(mediaStream);

      inputNode = source;

      vadProcessor = audioContext.createScriptProcessor(4096, 1, 1);
      vadProcessor.onaudioprocess = vadAudioProcess;

      source.connect(vadProcessor);
      vadProcessor.connect(audioContext.destination);

      recorder = new Recorder(source, { numChannels: 1 });

      vadRunning = false;
      setTimeout(() => {
        vadRunning = true;
        statusDiv.textContent = 'Listening for voice... Speak now.';
      }, 1000);
    } catch (err) {
      console.error('Error:', err);
      statusDiv.textContent = 'Microphone access error: ' + err.message;
      startBtn.disabled = false;
      stopBtn.disabled = true;
    }
  }

  function stopVoiceChat() {
    startBtn.disabled = false;
    stopBtn.disabled = true;
    statusDiv.textContent = 'Stopped.';
    vadRunning = false;
    clearTimeout(silenceTimeout);

    if (vadProcessor) {
      vadProcessor.disconnect();
      vadProcessor = null;
    }

    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop());
      mediaStream = null;
    }

    if (audioContext) {
      audioContext.close();
      audioContext = null;
    }

    isRecording = false;

    audioPlayback.pause();
    audioPlayback.src = '';
    audioPlayback.onended = null;
  }

  function vadAudioProcess(event) {
    if (!vadRunning) return;

    const inputData = event.inputBuffer.getChannelData(0);
    let sum = 0.0;
    for (let i = 0; i < inputData.length; i++) {
      sum += inputData[i] * inputData[i];
    }
    const rms = Math.sqrt(sum / inputData.length);

    if (rms > VAD_THRESHOLD) {
      statusDiv.textContent = 'Voice detected, recording...';
      if (silenceTimeout) {
        clearTimeout(silenceTimeout);
        silenceTimeout = null;
      }

      if (!isRecording) startRecording();
    } else {
      if (isRecording && !silenceTimeout) {
        silenceTimeout = setTimeout(() => {
          stopRecording();
          silenceTimeout = null;
        }, SILENCE_TIMEOUT);
        statusDiv.textContent = 'Silence detected, waiting...';
      }
    }
  }

  function startRecording() {
  if (!recorder) {
    // recreate recorder instance fresh each time you start recording
    recorder = new Recorder(inputNode, { numChannels: 1 });
  }
  isRecording = true;
  recorder.record();
}

function stopRecording() {
  if (!isRecording) return;
  isRecording = false;

  recorder.stop();
  recorder.exportWAV(blob => {
    recorder.clear();
    recorder = null; // clear recorder instance so next start creates fresh one
    handleRecordingStop(blob);
  });
}
  async function handleRecordingStop(wavBlob) {
    vadRunning = false;
    statusDiv.textContent = 'Processing audio...';

    try {
      const formData = new FormData();
      formData.append('file', wavBlob, 'audio.wav');

      const response = await fetch('https://speech-to-speech-spm6.onrender.com/voicechat', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) throw new Error('Server error: ' + response.statusText);

      const transcription = response.headers.get('X-Transcript') || '';
      statusDiv.textContent = `You said: "${transcription}". Playing response...`;

      const audioBlob = await response.blob();
      audioPlayback = new Audio(URL.createObjectURL(audioBlob));
      audioPlayback.play();

      audioPlayback.onended = () => {
        if (!vadRunning && mediaStream && audioContext && !isRecording) {
          const source = audioContext.createMediaStreamSource(mediaStream);

          vadProcessor = audioContext.createScriptProcessor(4096, 1, 1);
          vadProcessor.onaudioprocess = vadAudioProcess;

          source.connect(vadProcessor);
          vadProcessor.connect(audioContext.destination);

          recorder = new Recorder(source, { numChannels: 1 });

          vadRunning = true;
          statusDiv.textContent = 'Listening for voice... Speak now.';
        }
      };
    } catch (err) {
      statusDiv.textContent = 'Error: ' + err.message;
      vadRunning = true;
    }
  }
</script>

</body>
</html>
