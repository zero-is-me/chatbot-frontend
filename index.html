<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Voice Chat with VAD</title>
<style>
  body { font-family: Arial, sans-serif; margin: 2rem; }
  button { padding: 0.5rem 1rem; margin-right: 1rem; }
  #status { margin-top: 1rem; font-weight: bold; }
</style>
</head>
<body>

<button id="startBtn">Start Talking</button>
<button id="stopBtn" disabled>Stop</button>
<div id="status">Idle</div>

<script>
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const statusDiv = document.getElementById('status');

  let audioContext;
  let mediaStream;
  let mediaRecorder;
  let audioChunks = [];
  let vadProcessor;
  let vadRunning = false;
  let isRecording = false;
  let silenceTimeout;
  let audioPlayback = new Audio();

  const VAD_THRESHOLD = 0.05;  
  const SILENCE_DELAY = 1500;  

  startBtn.onclick = startVoiceChat;
  stopBtn.onclick = stopVoiceChat;

  async function startVoiceChat() {
  startBtn.disabled = true;
  stopBtn.disabled = false;
  statusDiv.textContent = 'Initializing microphone...';

  audioContext = new AudioContext();
  mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const source = audioContext.createMediaStreamSource(mediaStream);

  vadProcessor = audioContext.createScriptProcessor(4096, 1, 1);
  vadProcessor.onaudioprocess = vadAudioProcess;

  source.connect(vadProcessor);
  vadProcessor.connect(audioContext.destination);

  vadRunning = false;  
  setTimeout(() => {
    vadRunning = true;
    statusDiv.textContent = 'Listening for voice... Speak now.';
  }, 1000);  
}

  function stopVoiceChat() {
    startBtn.disabled = false;
    stopBtn.disabled = true;
    statusDiv.textContent = 'Stopped.';
    vadRunning = false;
    clearTimeout(silenceTimeout);

    if (vadProcessor) {
      vadProcessor.disconnect();
      vadProcessor.onaudioprocess = null;
      vadProcessor = null;
    }
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }
    if (mediaStream) {
      mediaStream.getTracks().forEach(track => track.stop());
      mediaStream = null;
    }
    if (audioContext) {
      audioContext.close();
      audioContext = null;
    }

    isRecording = false;

    audioPlayback.pause();
    audioPlayback.src = '';
    audioPlayback.onended = null;
  }

  let silenceTimer = null;
const SILENCE_TIMEOUT = 1000; 

function vadAudioProcess(event) {
  if (!vadRunning) return;

  const inputData = event.inputBuffer.getChannelData(0);
  let sum = 0.0;
  for (let i = 0; i < inputData.length; i++) {
    sum += inputData[i] * inputData[i];
  }
  const rms = Math.sqrt(sum / inputData.length);

  if (rms > VAD_THRESHOLD) {
    
    statusDiv.textContent = 'Voice detected, recording...';

    if (silenceTimer) {
      clearTimeout(silenceTimer);
      silenceTimer = null;
    }

    if (!isRecording) {
      startRecording();
    }
  } else {
    
    if (isRecording && !silenceTimer) {
    
      silenceTimer = setTimeout(() => {
        stopRecording();
        silenceTimer = null;
      }, SILENCE_TIMEOUT);

      statusDiv.textContent = 'Silence detected, waiting...';
    }
  }
}

  function startRecording() {
    audioChunks = [];
    mediaRecorder = new MediaRecorder(mediaStream);
    mediaRecorder.ondataavailable = e => {
      if (e.data.size > 0) audioChunks.push(e.data);
    };
    mediaRecorder.onstop = handleRecordingStop;
    mediaRecorder.start();
    isRecording = true;
  }

  function stopRecording() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
    }
    isRecording = false;
  }

  async function handleRecordingStop() {
    
    vadRunning = false;
    statusDiv.textContent = 'Processing audio...';

    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
    try {
      const formData = new FormData();
      formData.append('file', audioBlob, 'voice.webm');

      const response = await fetch('http://127.0.0.1:8000/voicechat', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) {
        throw new Error('Server error: ' + response.statusText);
      }

      const transcription = response.headers.get('X-Transcript') || '';
      statusDiv.textContent = `You said: "${transcription}". Playing response...`;

      const audioResponseBlob = await response.blob();
      audioPlayback.src = URL.createObjectURL(audioResponseBlob);

      audioPlayback.play();

      audioPlayback.onended = () => {
        if (vadRunning === false && mediaStream) {
          
          vadRunning = true;
          statusDiv.textContent = 'Listening for voice... Speak now.';
        }
      };

    } catch (error) {
      statusDiv.textContent = 'Error: ' + error.message;
      
      vadRunning = true;
    }
  }
</script>

</body>
</html>
