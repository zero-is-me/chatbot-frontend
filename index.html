<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interviewer (Simplified)</title>
    <!-- NO EXTERNAL VAD LIBRARY IS NEEDED OR LOADED -->

    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            background-color: #f0f2f5;
            color: #333;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            margin: 0;
        }
        .container {
            background-color: #ffffff;
            padding: 2rem 3rem;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            text-align: center;
            width: 90%;
            max-width: 600px;
        }
        h1 {
            color: #1a1a1a;
            margin-bottom: 1rem;
        }
        #status {
            margin-bottom: 1.5rem;
            font-size: 1.1rem;
            transition: color 0.3s ease;
            height: 20px;
        }
        .status-ready { color: #555; }
        .status-listening {
            color: #d9534f;
            font-weight: bold;
        }
        .status-processing { color: #0275d8; }
        .status-speaking { color: #5cb85c; }
        .status-error { color: #ff0000; font-weight: bold; }
        #transcript-container {
            height: 300px;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 1rem;
            overflow-y: auto;
            text-align: left;
            margin-bottom: 1.5rem;
            display: flex;
            flex-direction: column;
        }
        .message {
            padding: 0.75rem 1rem;
            border-radius: 18px;
            margin-bottom: 0.75rem;
            max-width: 80%;
            line-height: 1.4;
            word-wrap: break-word;
        }
        .user-message {
            background-color: #007bff;
            color: white;
            align-self: flex-end;
            border-bottom-right-radius: 4px;
        }
        .bot-message {
            background-color: #e9ecef;
            color: #333;
            align-self: flex-start;
            border-bottom-left-radius: 4px;
        }
        #control-button {
            background-color: #5cb85c;
            color: white;
            border: none;
            padding: 1rem 2rem;
            font-size: 1.2rem;
            border-radius: 8px;
            cursor: pointer;
            transition: background-color 0.3s ease, transform 0.1s ease;
        }
        #control-button:hover { background-color: #4cae4c; }
        #control-button:active { transform: scale(0.98); }
        #control-button:disabled { background-color: #cccccc; cursor: not-allowed; }
        #control-button.listening {
            background-color: #d9534f;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(217, 83, 79, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(217, 83, 79, 0); }
            100% { box-shadow: 0 0 0 0 rgba(217, 83, 79, 0); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Interviewer</h1>
        <div id="status" class="status-ready">Click "Start" to begin</div>
        <div id="transcript-container"></div>
        <button id="control-button">Start Interview</button>
    </div>

    <script>
        // --- CONFIGURATION ---
        const BACKEND_URL = "http://127.0.0.1:8000";

        // --- DOM ELEMENTS ---
        const statusDiv = document.getElementById("status");
        const controlButton = document.getElementById("control-button");
        const transcriptContainer = document.getElementById("transcript-container");

        // --- BROWSER API & STATE MANAGEMENT ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;
        let audioPlayer = new Audio();
        let isBotSpeaking = false;
        let finalTranscript = '';

        // --- INITIALIZATION ---
        if (!SpeechRecognition) {
            updateStatus("Speech Recognition is not supported in this browser.", "error");
            controlButton.disabled = true;
        } else {
            controlButton.addEventListener('click', handleControlButtonClick);
        }

        function initializeSpeechRecognition() {
            try {
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = true;

                recognition.onstart = () => {
                    updateStatus("Listening...", "listening");
                    controlButton.classList.add("listening");
                };

                recognition.onresult = (event) => {
                    let interimTranscript = '';
                    finalTranscript = '';
                    for (let i = event.resultIndex; i < event.results.length; ++i) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript;
                        } else {
                            interimTranscript += event.results[i][0].transcript;
                        }
                    }
                };

                recognition.onend = () => {
                    controlButton.classList.remove("listening");
                    if (isBotSpeaking) return;
                    
                    if (finalTranscript.trim()) {
                        updateStatus("Processing...", "processing");
                        processUserSpeech(finalTranscript);
                    } else {
                        updateStatus("Did not hear anything. Listening again.", "ready");
                        startListening();
                    }
                };
                
                recognition.onerror = (event) => {
                    if (event.error === 'no-speech') {
                        updateStatus("No speech detected. Listening again.", "ready");
                        startListening();
                    } else {
                        updateStatus(`Error: ${event.error}`, "error");
                        console.error("Speech recognition error:", event);
                    }
                };
                console.log("Speech Recognition Initialized");
                return true;
            } catch (err) {
                 updateStatus("Could not initialize speech recognition.", "error");
                 console.error("Initialization Error:", err);
                 return false;
            }
        }

        // --- CORE LOGIC ---
        function handleControlButtonClick() {
            if (!recognition) {
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        console.log("Microphone access granted.");
                        const success = initializeSpeechRecognition();
                        if (success) {
                            startInterview();
                        }
                    })
                    .catch(err => {
                        updateStatus("Microphone permission denied. Please enable it.", "error");
                        console.error("getUserMedia error:", err);
                    });
            }
        }
        
        async function startInterview() {
            controlButton.disabled = true;
            updateStatus("Starting session...", "processing");
            try {
                await fetch(`${BACKEND_URL}/reset`, { method: 'POST' });
                addMessage("Session reset. Starting interview.", "bot-message");

                const response = await fetch(`${BACKEND_URL}/start`);
                if (!response.ok) throw new Error("Failed to get greeting from backend.");
                
                addMessage("Hello! I'm your interviewer for today. To start, could you tell me a bit about your interests?", "bot-message");
                controlButton.textContent = 'Listening...';
                await playAudioFromStream(response.body);

            } catch (err) {
                updateStatus(`Error: ${err.message}`, "error");
                controlButton.disabled = false;
                controlButton.textContent = 'Start Interview';
            }
        }

        async function processUserSpeech(transcript) {
            addMessage(transcript, "user-message");
            await sendTextToBackend(transcript);
        }

        async function sendTextToBackend(text) {
            updateStatus("Thinking...", "processing");
            try {
                const response = await fetch(`${BACKEND_URL}/respond`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ text: text }),
                });
                if (!response.ok) throw new Error(`Server error: ${response.status}`);
                
                addMessage("...", "bot-message");
                await playAudioFromStream(response.body);

            } catch (err) {
                updateStatus(`Error: ${err.message}`, "error");
                startListening();
            }
        }

        function startListening() {
            if (!isBotSpeaking) {
                finalTranscript = '';
                recognition.start();
            }
        }

        // --- UTILITY FUNCTIONS ---
        async function playAudioFromStream(stream) {
            isBotSpeaking = true;
            recognition.abort();
            
            const reader = stream.getReader();
            const chunks = [];
            while (true) {
                const { done, value } = await reader.read();
                if (done) break;
                chunks.push(value);
            }
            const blob = new Blob(chunks, { type: 'audio/mpeg' });
            const url = URL.createObjectURL(blob);

            return new Promise((resolve) => {
                audioPlayer.src = url;
                audioPlayer.onplay = () => {
                    updateStatus("Bot is speaking...", "speaking");
                };
                audioPlayer.onended = () => {
                    isBotSpeaking = false;
                    startListening();
                    resolve();
                };
                audioPlayer.onerror = (e) => {
                    console.error("Audio player error:", e);
                    isBotSpeaking = false;
                    startListening();
                    resolve();
                };
                audioPlayer.play();
            });
        }

        function updateStatus(message, type) {
            statusDiv.textContent = message;
            statusDiv.className = `status status-${type}`;
        }

        function addMessage(text, className) {
            const lastMessage = transcriptContainer.querySelector(`.bot-message:last-child`);
            if (className === 'bot-message' && lastMessage && lastMessage.textContent === '...') {
                lastMessage.textContent = text;
            } else {
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${className}`;
                messageDiv.textContent = text;
                transcriptContainer.appendChild(messageDiv);
            }
            transcriptContainer.scrollTop = transcriptContainer.scrollHeight;
        }
    </script>
</body>
</html>
